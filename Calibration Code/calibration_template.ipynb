{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Methods and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook uses a template with a grid of april tags to calibrate a camera. The idea is to calculate the intrinsic and extrinsic parameters of the camera using the known values of the corners from the calibration tag grid then to use the calculated value as the initial guess for symforce's numerical optimizer by projecting points back onto the image using the calculated value and minimizing the error between the projected point and the known point to refine the calculated values of the intrinsic and extrinsic parameters of the camera. Overall, the results were good but there are many points, especially towards the edges, that do not track well. If tracked dots are going to be used as data, those errors will grow very large so a more robust estimation for the intial guess must be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For input/output\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# For numerical methods\n",
    "import numpy as np\n",
    "\n",
    "# For image processing and visualization of results\n",
    "import cv2\n",
    "from pupil_apriltags import Detector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For optimization with symforce\n",
    "import symforce\n",
    "symforce.set_epsilon_to_symbol()\n",
    "import symforce.symbolic as sf\n",
    "from symforce.values import Values\n",
    "from symforce.opt.factor import Factor\n",
    "from symforce.opt.optimizer import Optimizer\n",
    "import sym\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilizing image and template directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Where images are read from\n",
    "img_src_dir = Path(data_dir, 'calibration_images')\n",
    "\n",
    "# Where images are written to\n",
    "img_dst_dir = Path(data_dir, 'calibration_results')\n",
    "\n",
    "# Where the calibration template is located\n",
    "template_filename = Path(data_dir, 'tag36_11_grid_5x8-template.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting images into png format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for image_path in img_src_dir.iterdir():\n",
    "#     i += 1\n",
    "#     im = Image.open(image_path)\n",
    "#     im.save('{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get a tag with a particular ID from the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_with_id(tag_id, template):\n",
    "    for tag in template['tags']:\n",
    "        if tag['tag_id'] == tag_id:\n",
    "            return tag\n",
    "    raise Exception(f'tag_id {tag_id} not found in template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading tag grid template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(template_filename, 'r') as f:\n",
    "    template = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a tag detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_detector = Detector(\n",
    "    families=template['tag_family'],\n",
    "    nthreads=1,\n",
    "    quad_decimate=1.0,\n",
    "    quad_sigma=0.0,\n",
    "    refine_edges=1,\n",
    "    decode_sharpening=0.,\n",
    "    debug=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting tags in all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 : data/calibration_images/20240216_143519.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   1 : data/calibration_images/20240213_121702.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   2 : data/calibration_images/20240213_121701.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   3 : data/calibration_images/20240213_121704.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   4 : data/calibration_images/20240213_121700.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   5 : data/calibration_images/20240216_143510.jpg :  38 tags (  0 rejected) : 152 points \n",
      "   6 : data/calibration_images/20240216_143550.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   7 : data/calibration_images/20240213_121655.jpg :  40 tags (  0 rejected) : 160 points \n",
      "   8 : data/calibration_images/20240213_121703.png :  40 tags (  0 rejected) : 160 points \n",
      "   9 : data/calibration_images/20240213_121658.png :  40 tags (  0 rejected) : 160 points \n",
      "  10 : data/calibration_images/20240213_121701.png :  40 tags (  0 rejected) : 160 points \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WRN: Matrix is singular.\n",
      "WRN: Matrix is singular.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11 : data/calibration_images/20240216_143547.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  12 : data/calibration_images/20240213_121702.png :  40 tags (  0 rejected) : 160 points \n",
      "  13 : data/calibration_images/20240213_121658.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  14 : data/calibration_images/20240213_121703.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  15 : data/calibration_images/20240216_143555.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  16 : data/calibration_images/20240213_121704.png :  40 tags (  0 rejected) : 160 points \n",
      "  17 : data/calibration_images/20240216_143515.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  18 : data/calibration_images/20240216_143517.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  19 : data/calibration_images/20240213_212553.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  20 : data/calibration_images/20240216_143600.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  21 : data/calibration_images/20240216_143508.jpg :  40 tags (  0 rejected) : 160 points \n",
      "  22 : data/calibration_images/20240213_121700.png :  40 tags (  0 rejected) : 160 points \n"
     ]
    }
   ],
   "source": [
    "# Tag corners must be no less than this number of pixels from the image border\n",
    "buffer_px = 10\n",
    "\n",
    "# We are going to create a list of views, one per image\n",
    "views = []\n",
    "\n",
    "# Iterate over all images in the source directory\n",
    "for image_path in img_src_dir.iterdir():\n",
    "    # Skip anything that isn't a PNG file\n",
    "    # or image_path.suffix.lower() != '.jpg')\n",
    "    if (not image_path.is_file()):\n",
    "        continue\n",
    "\n",
    "    # Read image as grayscale\n",
    "    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Detect tags\n",
    "    tag_detections = tag_detector.detect(\n",
    "        img,\n",
    "        estimate_tag_pose=False,\n",
    "        camera_params=None,\n",
    "        tag_size=None,\n",
    "    )\n",
    "\n",
    "    # Get n point correspondences:\n",
    "    #\n",
    "    #  p (n x 3) is coordinates of each point in the tag frame\n",
    "    #  q (n x 2) is coordinates of each point in the image frame\n",
    "    #\n",
    "    rejected_tags = []\n",
    "    tags = []\n",
    "    p = []\n",
    "    q = []\n",
    "    for d in tag_detections:\n",
    "        # Reject tags with corners too close to the image boundary\n",
    "        if ((d.corners[:, 0] < buffer_px).any() or\n",
    "            (d.corners[:, 0] > (img.shape[1] - 1) - buffer_px).any() or\n",
    "            (d.corners[:, 1] < buffer_px).any() or\n",
    "            (d.corners[:, 1] > (img.shape[0] - 1) - buffer_px).any()):\n",
    "            continue\n",
    "        \n",
    "        # Add tag to list of detected tags\n",
    "        tags.append({\n",
    "            'tag_id': d.tag_id,\n",
    "            'corners': d.corners.tolist(),\n",
    "        })\n",
    "\n",
    "        # Add corners of tag to point correspondences\n",
    "        p.extend(get_tag_with_id(d.tag_id, template)['corners'])\n",
    "        q.extend(d.corners.tolist())\n",
    "    \n",
    "    # Make sure the lengths of p and q are consistent\n",
    "    assert(len(p) == len(q))\n",
    "    \n",
    "    # Count the number of tags and correspondences that were found\n",
    "    num_tags = len(tags)\n",
    "    num_points = len(p)\n",
    "\n",
    "    # Add to the list of views\n",
    "    views.append({\n",
    "        'image_name': str(image_path.name),\n",
    "        'num_tags': num_tags,\n",
    "        'tags': tags,\n",
    "        'num_points': num_points,\n",
    "        'p': p,\n",
    "        'q': q,\n",
    "    })\n",
    "    \n",
    "    # Show results\n",
    "    print(f' {len(views) - 1:3d} ' +\n",
    "          f': {str(image_path):30s} ' +\n",
    "          f': {num_tags:3d} tags ({len(rejected_tags):3d} rejected) ' +\n",
    "          f': {num_points:3d} points ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimate Parameters by Inspection was removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate intrinsic and extrinsic parameters by analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that implements the wedge operator (skew symmetric matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(v):\n",
    "    assert(type(v) == np.ndarray)\n",
    "    assert(v.shape == (3,))\n",
    "    return np.array([[0., -v[2], v[1]],\n",
    "                     [v[2], 0., -v[0]],\n",
    "                     [-v[1], v[0], 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to estimate the planar homography (i.e., $H$) between two sets of points. The \"source points\" (`pts_src`) are on the tag grid and are expressed in the coordinates of the world frame. The \"destination points\" (`pts_dst`) are in the image and are expressed in image coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homography(p, q):\n",
    "    A = []\n",
    "    n = len(q)\n",
    "    for i in range(n):\n",
    "        u, v, w = q[i]\n",
    "        A.append(np.row_stack((\n",
    "            np.hstack([np.zeros(3), -w*p[i].T, v*p[i].T]),\n",
    "            np.hstack([w*p[i].T, np.zeros(3), -u*p[i].T])\n",
    "        )))\n",
    "    A = np.array(A).reshape((2*n, 9))\n",
    "\n",
    "    U, S, VT = np.linalg.svd(A)\n",
    "    vn = VT[-1].reshape((9,1))\n",
    "    assert(np.allclose(A@vn, np.zeros((2*n,1)), atol=1e-3))\n",
    "    \n",
    "    H = vn.reshape((3,3))\n",
    "    return H/np.linalg.norm(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get the homography for each view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homographies(views):\n",
    "    homographies = []\n",
    "    for view in views:\n",
    "        # Get src points (tag)\n",
    "        pts_src = []\n",
    "        for p in view['p']:\n",
    "            pts_src.append(np.append(p[:-1], [1.]))\n",
    "        pts_src = np.array(pts_src)\n",
    "\n",
    "        # Get dst points (img)\n",
    "        pts_dst = []\n",
    "        for q in view['q']:\n",
    "            pts_dst.append(np.append(q, [1.]))\n",
    "        pts_dst = np.array(pts_dst)\n",
    "\n",
    "        # Get homography\n",
    "        homographies.append(get_homography(pts_src, pts_dst))\n",
    "\n",
    "    return np.array(homographies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get the intrinsic parameters (i.e., the intrinsic camera matrix $K$), given homographies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m(a, c):\n",
    "    assert(a.shape == (3,))\n",
    "    assert(c.shape == (3,))\n",
    "    a1, a2, a3 = a\n",
    "    c1, c2, c3 = c\n",
    "    m  = np.array([a1*c1, a2*c2, a3*c3, a1*c2+a2*c1, a2*c3+a3*c2, a3*c1+a1*c3])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsic_parameters(homographies):\n",
    "    M = []\n",
    "    n = len(homographies)\n",
    "    for i in range(n):\n",
    "        h1 = homographies[i][:,0]\n",
    "        h2 = homographies[i][:,1]\n",
    "        h3 = homographies[i][:,2]\n",
    "\n",
    "        Mn = np.array([get_m(h1, h2), get_m(h1, h1) - get_m(h2, h2)])\n",
    "        M.append(Mn)\n",
    "        \n",
    "    M = np.array(M).reshape((2*n, 6))\n",
    "\n",
    "    U, S, VT = np.linalg.svd(M)\n",
    "    b1, b2, b3, b4, b5, b6 = VT[-1]\n",
    "\n",
    "    B = np.array([[b1, b4, b6],\n",
    "                  [b4, b2, b5],\n",
    "                  [b6, b5, b3]])\n",
    "    assert(np.allclose(B, B.T))\n",
    "\n",
    "    A = np.linalg.cholesky(B).T\n",
    "    K = np.linalg.inv(A)\n",
    "   \n",
    "    return K/K[-1,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get the extrinsic parameters (i.e., the camera pose for each view), given homographies and intrinsic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extrinsic_parameters(homographies, K):\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    n = len(homographies)\n",
    "    poses = []\n",
    "\n",
    "    for i in range(n):\n",
    "        h1 = homographies[i][:,0]\n",
    "        h2 = homographies[i][:,1]\n",
    "        h3 = homographies[i][:,2]\n",
    "        s = 1/np.linalg.norm(K_inv@h1)\n",
    "        x_inC_ofW = s*K_inv@h1\n",
    "        y_inC_ofW = s*K_inv@h2\n",
    "        z_inC_ofW = skew(x_inC_ofW)@y_inC_ofW\n",
    "        Q = np.vstack((x_inC_ofW, y_inC_ofW, z_inC_ofW)).T\n",
    "\n",
    "        U, S, VT = np.linalg.svd(Q)\n",
    "        R_inC_ofW = U@VT\n",
    "        p_inC_ofW = s*K_inv@h3\n",
    "\n",
    "        T_inC_ofW=  np.row_stack([\n",
    "            np.column_stack([R_inC_ofW, p_inC_ofW]),\n",
    "            np.array([0., 0., 0., 1.]),])\n",
    "        poses.append(T_inC_ofW)\n",
    "    return np.array(poses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply code to perform intrinsic and extrinsic calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "homographies = get_homographies(views)\n",
    "K = get_intrinsic_parameters(homographies)\n",
    "poses = get_extrinsic_parameters(homographies, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K\n",
      "[[ 4218.2491     2.2201  1593.6232]\n",
      " [    0.0000  4224.9318  2032.7124]\n",
      " [    0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143519.jpg\n",
      "[[   -0.0170    -0.9998     0.0053     0.0710]\n",
      " [   -0.9945     0.0164    -0.1033     0.1071]\n",
      " [    0.1032    -0.0070    -0.9946    -0.2940]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121702.jpg\n",
      "[[   -0.0057    -0.9978     0.0665     0.0792]\n",
      " [   -1.0000     0.0056    -0.0011     0.1187]\n",
      " [    0.0008    -0.0665    -0.9978    -0.2842]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121701.jpg\n",
      "[[   -0.0087    -0.9953     0.0968     0.0862]\n",
      " [   -1.0000     0.0090     0.0022     0.1176]\n",
      " [   -0.0030    -0.0967    -0.9953    -0.2821]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121704.jpg\n",
      "[[   -0.0023    -0.9997     0.0257     0.0692]\n",
      " [   -0.9984     0.0038     0.0564     0.1218]\n",
      " [   -0.0564    -0.0255    -0.9981    -0.2729]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121700.jpg\n",
      "[[   -0.0066    -0.9989     0.0469     0.0765]\n",
      " [   -1.0000     0.0066    -0.0012     0.1158]\n",
      " [    0.0009    -0.0469    -0.9989    -0.2851]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143510.jpg\n",
      "[[   -0.0014    -0.9999     0.0146     0.0712]\n",
      " [   -0.9988     0.0007    -0.0497     0.1166]\n",
      " [    0.0497    -0.0147    -0.9987    -0.2779]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143550.jpg\n",
      "[[   -0.0570    -0.9983    -0.0149     0.0831]\n",
      " [   -0.9968     0.0577    -0.0558     0.1167]\n",
      " [    0.0565     0.0117    -0.9983    -0.2881]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121655.jpg\n",
      "[[    0.0010    -0.9989     0.0461     0.0764]\n",
      " [   -0.9931     0.0044     0.1171     0.1212]\n",
      " [   -0.1172    -0.0459    -0.9921    -0.2744]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121703.png\n",
      "[[   -0.0097    -0.9997     0.0224     0.0694]\n",
      " [   -0.9999     0.0095    -0.0078     0.1167]\n",
      " [    0.0076    -0.0224    -0.9997    -0.2879]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121658.png\n",
      "[[    0.0003    -0.9987     0.0516     0.0745]\n",
      " [   -0.9976    -0.0039    -0.0692     0.1114]\n",
      " [    0.0693    -0.0515    -0.9963    -0.2918]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121701.png\n",
      "[[   -0.0087    -0.9953     0.0968     0.0862]\n",
      " [   -1.0000     0.0090     0.0022     0.1176]\n",
      " [   -0.0030    -0.0968    -0.9953    -0.2821]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143547.jpg\n",
      "[[   -0.0057    -0.9993     0.0375     0.0761]\n",
      " [   -0.9971     0.0028    -0.0763     0.1186]\n",
      " [    0.0761    -0.0379    -0.9964    -0.2893]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121702.png\n",
      "[[   -0.0057    -0.9978     0.0665     0.0792]\n",
      " [   -1.0000     0.0056    -0.0011     0.1187]\n",
      " [    0.0008    -0.0665    -0.9978    -0.2842]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121658.jpg\n",
      "[[    0.0003    -0.9987     0.0516     0.0745]\n",
      " [   -0.9976    -0.0039    -0.0692     0.1114]\n",
      " [    0.0693    -0.0515    -0.9963    -0.2918]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121703.jpg\n",
      "[[   -0.0097    -0.9997     0.0224     0.0694]\n",
      " [   -0.9999     0.0095    -0.0078     0.1167]\n",
      " [    0.0076    -0.0224    -0.9997    -0.2879]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143555.jpg\n",
      "[[   -0.0243    -0.9957     0.0892     0.0822]\n",
      " [   -0.9997     0.0233    -0.0115     0.1208]\n",
      " [    0.0093    -0.0894    -0.9959    -0.2906]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121704.png\n",
      "[[   -0.0023    -0.9997     0.0257     0.0692]\n",
      " [   -0.9984     0.0038     0.0564     0.1218]\n",
      " [   -0.0564    -0.0255    -0.9981    -0.2729]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143515.jpg\n",
      "[[    0.0064    -0.9990     0.0446     0.0733]\n",
      " [   -0.9997    -0.0074    -0.0217     0.1225]\n",
      " [    0.0220    -0.0444    -0.9988    -0.2711]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143517.jpg\n",
      "[[   -0.0046    -0.9967     0.0811     0.0825]\n",
      " [   -0.9966    -0.0021    -0.0821     0.1105]\n",
      " [    0.0820    -0.0813    -0.9933    -0.2854]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_212553.jpg\n",
      "[[   -0.0119    -0.9999     0.0073     0.0647]\n",
      " [   -0.9982     0.0114    -0.0583     0.1167]\n",
      " [    0.0582    -0.0080    -0.9983     0.3041]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143600.jpg\n",
      "[[    0.0029    -0.9994    -0.0345     0.0685]\n",
      " [   -0.9992    -0.0015    -0.0396     0.1236]\n",
      " [    0.0395     0.0346    -0.9986    -0.2900]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240216_143508.jpg\n",
      "[[    0.0034    -0.9998     0.0171     0.0717]\n",
      " [   -0.9991    -0.0041    -0.0418     0.1167]\n",
      " [    0.0419    -0.0169    -0.9990    -0.2795]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n",
      "Camera pose for image 20240213_121700.png\n",
      "[[   -0.0066    -0.9989     0.0469     0.0765]\n",
      " [   -1.0000     0.0066    -0.0012     0.1158]\n",
      " [    0.0009    -0.0469    -0.9989    -0.2851]\n",
      " [    0.0000     0.0000     0.0000     1.0000]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(linewidth=150, formatter={'float': lambda x: f'{x:10.4f}'}):\n",
    "    print('K')\n",
    "    print(K)\n",
    "    print('')\n",
    "\n",
    "for view, pose in zip(views, poses):\n",
    "    with np.printoptions(linewidth=150, formatter={'float': lambda x: f'{x:10.4f}'}):\n",
    "        print(f'Camera pose for image {view[\"image_name\"]}')\n",
    "        print(pose)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate intrinsic and extrinsic parameters by optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a symbolic function that projects a point into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(\n",
    "    T: sf.Pose3,\n",
    "    p: sf.V3,\n",
    "    fx: sf.Scalar,\n",
    "    fy: sf.Scalar,\n",
    "    cx: sf.Scalar,\n",
    "    cy: sf.Scalar,\n",
    "    epsilon: sf.Scalar,\n",
    ") -> sf.V2:\n",
    "    return sf.V2((T*p)[0]*fx/(T*p)[2] + cx, (T*p)[1]*fy/(T*p)[2] + cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a symbolic function that computes the difference between a projected point and an image point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_residual(\n",
    "    T: sf.Pose3,\n",
    "    p: sf.V3,\n",
    "    q: sf.V2,\n",
    "    fx: sf.Scalar,\n",
    "    fy: sf.Scalar,\n",
    "    cx: sf.Scalar,\n",
    "    cy: sf.Scalar,\n",
    "    epsilon: sf.Scalar,  \n",
    ") -> sf.V2:\n",
    "    return sf.V2([q[0] - ((T*p)[0]*fx/(T*p)[2] + cx), q[1] - ((T*p)[1]*fy/(T*p)[2] + cy)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambdify these two functions so they can be evaluated numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_num = symforce.util.lambdify(projection)\n",
    "projection_residual_num = symforce.util.lambdify(projection_residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create initial values for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_values = Values(\n",
    "    views=[],               # <-- fill this list with initial values specific to each view\n",
    "    fx=K[0, 0],             # <-- initial guess at fx\n",
    "    fy=K[1, 1],             # <-- initial guess at fy\n",
    "    cx=K[0, 2],             # <-- initial guess at cx\n",
    "    cy=K[1, 2],             # <-- initial guess at cy\n",
    "    epsilon=sym.epsilon,    # <-- constant parameter required by symforce\n",
    ")\n",
    "\n",
    "# Iterate over each view (along with each camera pose estimate)\n",
    "for view, pose in zip(views, poses):\n",
    "    view_values = Values(\n",
    "        T=sym.Pose3(        # <-- initial guess at camera pose\n",
    "            R=sym.Rot3.from_rotation_matrix(pose[0:3, 0:3]),\n",
    "            t=pose[0:3, 3],\n",
    "        ),\n",
    "        matches=[],         # <-- fill this list with initial values specific to each match\n",
    "    )\n",
    "\n",
    "    # Iterate over each match (i.e., each point correspondence)\n",
    "    for p, q in zip(view['p'], view['q']):\n",
    "        view_values['matches'].append(Values(p=np.array(p), q=np.array(q)))\n",
    "    \n",
    "    # Append the initial values we just created to the list of views\n",
    "    initial_values['views'].append(view_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create factors for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = []\n",
    "for i_view, view in enumerate(initial_values['views']):\n",
    "    for i_match, match in enumerate(view['matches']):\n",
    "        factors.append(Factor(\n",
    "            residual=projection_residual,\n",
    "            keys=[\n",
    "                f'views[{i_view}].T',\n",
    "                f'views[{i_view}].matches[{i_match}].p',\n",
    "                f'views[{i_view}].matches[{i_match}].q',\n",
    "                'fx',\n",
    "                'fy',\n",
    "                'cx',\n",
    "                'cy',\n",
    "                'epsilon',\n",
    "            ]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_keys = ['fx', 'fy', 'cx', 'cy',]\n",
    "for i_view, view in enumerate(initial_values['views']):\n",
    "    optimized_keys.append(f'views[{i_view}].T')\n",
    "optimizer = Optimizer(\n",
    "    factors=factors,\n",
    "    optimized_keys=optimized_keys,\n",
    "    debug_stats=True,\n",
    "    params=Optimizer.Params(\n",
    "        iterations=100,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-03 17:15:10.761] [info] LM<sym::Optimize> [iter    0] lambda: 1.000e+00, error prev/linear/new: 35456.128/0.000/30095.088, rel reduction: 0.15120\n",
      "[2024-04-03 17:15:13.496] [info] LM<sym::Optimize> [iter    1] lambda: 2.500e-01, error prev/linear/new: 30095.087/0.000/30069.744, rel reduction: 0.00084\n",
      "[2024-04-03 17:15:16.169] [info] LM<sym::Optimize> [iter    2] lambda: 6.250e-02, error prev/linear/new: 30069.745/0.000/30058.354, rel reduction: 0.00038\n",
      "[2024-04-03 17:15:18.735] [info] LM<sym::Optimize> [iter    3] lambda: 1.562e-02, error prev/linear/new: 30058.353/0.000/30040.008, rel reduction: 0.00061\n",
      "[2024-04-03 17:15:21.429] [info] LM<sym::Optimize> [iter    4] lambda: 3.906e-03, error prev/linear/new: 30040.007/0.000/29986.391, rel reduction: 0.00178\n",
      "[2024-04-03 17:15:24.067] [info] LM<sym::Optimize> [iter    5] lambda: 9.766e-04, error prev/linear/new: 29986.390/0.000/29901.307, rel reduction: 0.00284\n",
      "[2024-04-03 17:15:26.901] [info] LM<sym::Optimize> [iter    6] lambda: 2.441e-04, error prev/linear/new: 29901.306/0.000/29860.285, rel reduction: 0.00137\n",
      "[2024-04-03 17:15:29.542] [info] LM<sym::Optimize> [iter    7] lambda: 6.104e-05, error prev/linear/new: 29860.286/0.000/29855.809, rel reduction: 0.00015\n",
      "[2024-04-03 17:15:32.226] [info] LM<sym::Optimize> [iter    8] lambda: 1.526e-05, error prev/linear/new: 29855.809/0.000/29855.703, rel reduction: 0.00000\n",
      "[2024-04-03 17:15:35.227] [info] LM<sym::Optimize> [iter    9] lambda: 3.815e-06, error prev/linear/new: 29855.703/0.000/29855.701, rel reduction: 0.00000\n"
     ]
    }
   ],
   "source": [
    "result = optimizer.optimize(initial_values)\n",
    "assert(result.status == Optimizer.Status.SUCCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show sum-squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum-squared error (halved), before optimization: 35456.1 pixels\n",
      "Sum-squared error (halved), after optimization: 29855.7 pixels\n"
     ]
    }
   ],
   "source": [
    "# Compute all errors before optimization\n",
    "initial_errors = []\n",
    "for view in result.initial_values['views']:\n",
    "    for match in view['matches']:\n",
    "        initial_errors.append(np.linalg.norm(projection_residual_num(\n",
    "            view['T'],\n",
    "            match['p'],\n",
    "            match['q'],\n",
    "            result.initial_values['fx'],\n",
    "            result.initial_values['fy'],\n",
    "            result.initial_values['cx'],\n",
    "            result.initial_values['cy'],\n",
    "            result.initial_values['epsilon'],\n",
    "        )))\n",
    "initial_errors = np.array(initial_errors)\n",
    "\n",
    "# Compute all errors after optimization\n",
    "final_errors = []\n",
    "for view in result.optimized_values['views']:\n",
    "    for match in view['matches']:\n",
    "        final_errors.append(np.linalg.norm(projection_residual_num(\n",
    "            view['T'],\n",
    "            match['p'],\n",
    "            match['q'],\n",
    "            result.optimized_values['fx'],\n",
    "            result.optimized_values['fy'],\n",
    "            result.optimized_values['cx'],\n",
    "            result.optimized_values['cy'],\n",
    "            result.optimized_values['epsilon'],\n",
    "        )))\n",
    "final_errors = np.array(final_errors)\n",
    "\n",
    "# Compute sum-squared errors\n",
    "print(f'Sum-squared error (halved), before optimization: {0.5 * np.sum(initial_errors**2):.1f} pixels')\n",
    "print(f'Sum-squared error (halved), after optimization: {0.5 * np.sum(final_errors**2):.1f} pixels')\n",
    "assert(np.isclose(0.5 * np.sum(final_errors**2), result.error()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show error histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(initial_errors, alpha=0.5, label='before optimization')\n",
    "ax.hist(final_errors, alpha=0.5, label='after optimization')\n",
    "ax.legend()\n",
    "ax.set_xlabel('error (pixels)')\n",
    "ax.set_ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save annotated images to show match (hopefully) between given and projected image points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/calibration_images/20240216_143519.jpg -> data/calibration_results/20240216_143519.jpg\n",
      "data/calibration_images/20240213_121702.jpg -> data/calibration_results/20240213_121702.jpg\n",
      "data/calibration_images/20240213_121701.jpg -> data/calibration_results/20240213_121701.jpg\n",
      "data/calibration_images/20240213_121704.jpg -> data/calibration_results/20240213_121704.jpg\n",
      "data/calibration_images/20240213_121700.jpg -> data/calibration_results/20240213_121700.jpg\n",
      "data/calibration_images/20240216_143510.jpg -> data/calibration_results/20240216_143510.jpg\n",
      "data/calibration_images/20240216_143550.jpg -> data/calibration_results/20240216_143550.jpg\n",
      "data/calibration_images/20240213_121655.jpg -> data/calibration_results/20240213_121655.jpg\n",
      "data/calibration_images/20240213_121703.png -> data/calibration_results/20240213_121703.png\n",
      "data/calibration_images/20240213_121658.png -> data/calibration_results/20240213_121658.png\n",
      "data/calibration_images/20240213_121701.png -> data/calibration_results/20240213_121701.png\n",
      "data/calibration_images/20240216_143547.jpg -> data/calibration_results/20240216_143547.jpg\n",
      "data/calibration_images/20240213_121702.png -> data/calibration_results/20240213_121702.png\n",
      "data/calibration_images/20240213_121658.jpg -> data/calibration_results/20240213_121658.jpg\n",
      "data/calibration_images/20240213_121703.jpg -> data/calibration_results/20240213_121703.jpg\n",
      "data/calibration_images/20240216_143555.jpg -> data/calibration_results/20240216_143555.jpg\n",
      "data/calibration_images/20240213_121704.png -> data/calibration_results/20240213_121704.png\n",
      "data/calibration_images/20240216_143515.jpg -> data/calibration_results/20240216_143515.jpg\n",
      "data/calibration_images/20240216_143517.jpg -> data/calibration_results/20240216_143517.jpg\n",
      "data/calibration_images/20240213_212553.jpg -> data/calibration_results/20240213_212553.jpg\n",
      "data/calibration_images/20240216_143600.jpg -> data/calibration_results/20240216_143600.jpg\n",
      "data/calibration_images/20240216_143508.jpg -> data/calibration_results/20240216_143508.jpg\n",
      "data/calibration_images/20240213_121700.png -> data/calibration_results/20240213_121700.png\n"
     ]
    }
   ],
   "source": [
    "# Choose parameters for annotation\n",
    "text_offset = 10\n",
    "mark_radius = 10\n",
    "text_scale = 1\n",
    "text_thickness = 3\n",
    "text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "text_linetype = cv2.LINE_AA\n",
    "\n",
    "# Iterate over all views\n",
    "for view_data, view_initial, view_final in zip(views, result.initial_values['views'], result.optimized_values['views']):\n",
    "    # Image paths\n",
    "    img_src_path = Path(img_src_dir, view_data['image_name'])\n",
    "    img_dst_path = Path(img_dst_dir, view_data['image_name'])\n",
    "    print(f'{img_src_path} -> {img_dst_path}')\n",
    "\n",
    "    # Read image as BGR\n",
    "    img = cv2.imread(str(img_src_path))\n",
    "    \n",
    "    # Add annotations to image\n",
    "    for i_match, match in enumerate(view_final['matches']):\n",
    "        # Get the image point that was given\n",
    "        q = match['q']\n",
    "        \n",
    "        # Get the image point that was computed by projection (before optimization)\n",
    "        q_initial = projection_num(\n",
    "            view_initial['T'],\n",
    "            match['p'],\n",
    "            result.initial_values['fx'],\n",
    "            result.initial_values['fy'],\n",
    "            result.initial_values['cx'],\n",
    "            result.initial_values['cy'],\n",
    "            result.initial_values['epsilon'],\n",
    "        )\n",
    "\n",
    "        # Get the image point that was computed by projection (after optimization)\n",
    "        q_final = projection_num(\n",
    "            view_final['T'],\n",
    "            match['p'],\n",
    "            result.optimized_values['fx'],\n",
    "            result.optimized_values['fy'],\n",
    "            result.optimized_values['cx'],\n",
    "            result.optimized_values['cy'],\n",
    "            result.optimized_values['epsilon'],\n",
    "        )\n",
    "\n",
    "        # Mark and number the image point that was given\n",
    "        cv2.circle(\n",
    "            img,\n",
    "            (int(q[0]), int(q[1])),\n",
    "            2 * mark_radius,\n",
    "            (0, 0, 255),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'{i_match}',\n",
    "            (int(q[0]) + text_offset, int(q[1]) + 4 * text_offset),\n",
    "            text_font,\n",
    "            text_scale,\n",
    "            (0, 0, 255),\n",
    "            text_thickness,\n",
    "            text_linetype,\n",
    "        )\n",
    "        \n",
    "        # Mark and number the image point that was computed by projection (before optimization)\n",
    "        cv2.circle(\n",
    "            img,\n",
    "            (int(q_initial[0]), int(q_initial[1])),\n",
    "            int(1.5 * mark_radius),\n",
    "            (0, 255, 0),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'{i_match}',\n",
    "            (int(q_initial[0]) - 4 * text_offset, int(q_initial[1]) - 2 * text_offset),\n",
    "            text_font,\n",
    "            text_scale,\n",
    "            (0, 255, 0),\n",
    "            text_thickness,\n",
    "            text_linetype,\n",
    "        )\n",
    "\n",
    "        # Mark and number the image point that was computed by projection (after optimization)\n",
    "        cv2.circle(\n",
    "            img,\n",
    "            (int(q_final[0]), int(q_final[1])),\n",
    "            mark_radius,\n",
    "            (255, 0, 0),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'{i_match}',\n",
    "            (int(q_final[0]) + text_offset, int(q_final[1]) - 2 * text_offset),\n",
    "            text_font,\n",
    "            text_scale,\n",
    "            (255, 0, 0),\n",
    "            text_thickness,\n",
    "            text_linetype,\n",
    "        )\n",
    "\n",
    "    cv2.imwrite(str(img_dst_path), img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
